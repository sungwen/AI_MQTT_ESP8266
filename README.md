```
from flask import Flask, Response, render_template_string, request, jsonify
import cv2
import paho.mqtt.client as mqtt
import json
import threading
import speech_recognition as sr
import datetime

# MQTT ä¼ºæœå™¨è¨­å®š
MQTT_BROKER = "demo.thingsboard.io"
MQTT_TOPIC_TELEMETRY = "v1/devices/me/telemetry"
TOKEN = "7z0y91k7lew58lir3mlx"

# å»ºç«‹ MQTT å®¢æˆ¶ç«¯
mqtt_client = mqtt.Client(client_id="AI_Camera", callback_api_version=1)
mqtt_client.username_pw_set(TOKEN)
mqtt_client.connect(MQTT_BROKER, 1883, 60)
mqtt_client.loop_start()

# ç‹€æ…‹è®Šæ•¸
light_status = "æœªçŸ¥"
voice_status = "æœªå•Ÿå‹•"
voice_thread = None
stop_voice_control = False

# è¨‚é–±ç‡ˆå…‰ç‹€æ…‹
def on_message(client, userdata, message):
    global light_status
    try:
        payload = json.loads(message.payload.decode())
        if "TurnOnLight" in payload:
            light_status = "é–‹ç‡ˆ" if payload["TurnOnLight"] else "é—œç‡ˆ"
    except json.JSONDecodeError:
        print("âŒ è§£æ MQTT è¨Šæ¯å¤±æ•—")

mqtt_client.subscribe(MQTT_TOPIC_TELEMETRY)
mqtt_client.on_message = on_message

# Flask Web ä¼ºæœå™¨
app = Flask(__name__)

# åˆå§‹åŒ– Webcam
camera = cv2.VideoCapture(0)

# äººè‡‰åµæ¸¬æ¨¡å‹
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# å½±åƒä¸²æµå‡½æ•¸ï¼ŒåŒ…å« AI åµæ¸¬æ¨™è¨˜æ¡†
def generate_frames():
    while True:
        success, frame = camera.read()
        if not success:
            break

        # è½‰æ›ç‚ºç°éšåœ–åƒä»¥é€²è¡Œäººè‡‰åµæ¸¬
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # ç¹ªè£½æ¨™è¨˜æ¡†
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        _, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

# AI å½±åƒä¸²æµ API
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

# å–å¾—ç‹€æ…‹ API
@app.route('/status')
def get_status():
    return jsonify(light_status=light_status, voice_status=voice_status)

# å•Ÿå‹• / åœæ­¢ èªéŸ³æ§åˆ¶
@app.route('/voice_control', methods=["POST"])
def toggle_voice():
    global voice_thread, stop_voice_control, voice_status
    action = request.json.get("action")

    if action == "start":
        stop_voice_control = False
        if voice_thread is None:
            voice_thread = threading.Thread(target=voice_control, daemon=True)
            voice_thread.start()
        voice_status = "å·²å•Ÿå‹•"
    elif action == "stop":
        stop_voice_control = True
        voice_thread = None
        voice_status = "å·²åœæ­¢"

    return jsonify(status=voice_status)

# æ‰‹å‹•é–‹é—œç‡ˆ API
@app.route('/toggle_light', methods=["POST"])
def toggle_light():
    action = request.json.get("action")
    if action == "on":
        mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": True}}))
    elif action == "off":
        mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": False}}))
    return jsonify(status="ç‡ˆå…‰å·²è®Šæ›´")

# èªéŸ³æ§åˆ¶å‡½æ•¸
def voice_control():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    while not stop_voice_control:
        with mic as source:
            print("ğŸ¤ èªéŸ³æ§åˆ¶ä¸­ï¼Œè«‹èªªï¼šé–‹ç‡ˆ / é—œç‡ˆ...")
            recognizer.adjust_for_ambient_noise(source, duration=1)
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=3)

        try:
            command = recognizer.recognize_google(audio, language="zh-TW")
            print(f"âœ… è¾¨è­˜æˆåŠŸ: {command}")

            if "é–‹ç‡ˆ" in command:
                mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": True}}))
            elif "é—œç‡ˆ" in command:
                mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": False}}))
        except sr.UnknownValueError:
            print("âŒ èªéŸ³è¾¨è­˜å¤±æ•—")
        except sr.RequestError:
            print("âŒ ç„¡æ³•é€£ç·šè‡³ Google Speech API")

# ç¶²é é¦–é 
@app.route('/')
def home():
    return render_template_string('''
        <html>
        <head>
            <title>AI Camera & ESP8266 Control</title>
            <script>
                function updateStatus() {
                    fetch('/status')
                        .then(response => response.json())
                        .then(data => {
                            document.getElementById('status').innerText = "ç‡ˆå…‰ç‹€æ…‹: " + data.light_status;
                            document.getElementById('voice_status').innerText = "èªéŸ³æ§åˆ¶: " + data.voice_status;
                        });
                }
                function toggleVoice(action) {
                    fetch('/voice_control', {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify({ action: action })
                    }).then(response => response.json())
                      .then(data => {
                          document.getElementById('voice_status').innerText = "èªéŸ³æ§åˆ¶: " + data.status;
                          alert("èªéŸ³æ§åˆ¶: " + data.status);
                      });
                }
                function toggleLight(action) {
                    fetch('/toggle_light', {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify({ action: action })
                    }).then(response => response.json())
                      .then(data => {
                          alert(data.status);
                      });
                }
                setInterval(updateStatus, 2000);
            </script>
        </head>
        <body>
            <h1>AI Camera & ESP8266 Control</h1>
            <img src="/video_feed"><br><br>
            <h2 id="status">ç‡ˆå…‰ç‹€æ…‹: è®€å–ä¸­...</h2>
            <h2 id="voice_status">èªéŸ³æ§åˆ¶: æœªå•Ÿå‹•</h2>
            <button onclick="toggleVoice('start')">å•Ÿå‹•èªéŸ³æ§åˆ¶</button>
            <button onclick="toggleVoice('stop')">åœæ­¢èªéŸ³æ§åˆ¶</button>
            <br><br>
            <button onclick="toggleLight('on')">é–‹ç‡ˆ</button>
            <button onclick="toggleLight('off')">é—œç‡ˆ</button>
        </body>
        </html>
    ''')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
```
# ğŸ“Œ ç¨‹å¼ç¢¼è¬›è§£
é€™æ®µç¨‹å¼ç¢¼çš„åŠŸèƒ½æ˜¯ é€é Flask ç¶²é ä»‹é¢ ä¾†æ§åˆ¶ ESP8266 é–‹é—œç‡ˆï¼Œä¸¦ä¸” é€é Webcam é€²è¡Œ AI åµæ¸¬ ä»¥åŠ èªéŸ³è¾¨è­˜ä¾†é–‹é—œç‡ˆã€‚

## ğŸ“Œ 1. å°å…¥å¿…è¦çš„ Python æ¨¡çµ„
```
from flask import Flask, Response, render_template_string, request, jsonify
import cv2
import paho.mqtt.client as mqtt
import json
import threading
import speech_recognition as sr
import datetime
```
* Flaskï¼šå»ºç«‹ Web ä¼ºæœå™¨
* cv2 (OpenCV)ï¼šè™•ç† Webcam å½±åƒ + AI äººè‡‰åµæ¸¬
* paho.mqtt.clientï¼šèˆ‡ ESP8266 é€é MQTT é€²è¡Œé€šè¨Š
* jsonï¼šè™•ç†è³‡æ–™å°è£
* threadingï¼šç”¨ä¾†è®“èªéŸ³æ§åˆ¶é‹è¡Œåœ¨èƒŒæ™¯
* speech_recognitionï¼šç”¨ä¾†è™•ç†èªéŸ³è¾¨è­˜

## ğŸ“Œ 2. MQTT é€£ç·šè¨­å®š
```
MQTT_BROKER = "demo.thingsboard.io"
MQTT_TOPIC_TELEMETRY = "v1/devices/me/telemetry"
TOKEN = "7z0y91k7lew58lir3mlx"

mqtt_client = mqtt.Client(client_id="AI_Camera", callback_api_version=1)
mqtt_client.username_pw_set(TOKEN)
mqtt_client.connect(MQTT_BROKER, 1883, 60)
mqtt_client.loop_start()
```light_status = "æœªçŸ¥"
voice_status = "æœªå•Ÿå‹•"
voice_thread = None
stop_voice_control = False
```
* MQTT_BROKERï¼šé€™æ˜¯ ThingsBoard MQTT ä¼ºæœå™¨ï¼ˆæˆ–å…¶ä»– MQTT ä¼ºæœå™¨çš„ IPï¼‰ã€‚
* TOKENï¼šé€™æ˜¯ ThingsBoard è£ç½®æˆæ¬Š Tokenï¼Œä½ éœ€è¦å¡«å¯« ä½ è‡ªå·±çš„ Tokenã€‚
* mqtt_client.loop_start()ï¼šè®“ MQTT æŒçºŒé‹è¡Œï¼Œæ¥æ”¶ä¾†è‡ª ThingsBoard çš„è¨Šæ¯ã€‚

## ğŸ“Œ 3. ç‡ˆå…‰èˆ‡èªéŸ³æ§åˆ¶çš„ç‹€æ…‹è®Šæ•¸
```
light_status = "æœªçŸ¥"
voice_status = "æœªå•Ÿå‹•"
voice_thread = None
stop_voice_control = False
```
* light_statusï¼šå­˜å„²ç‡ˆå…‰çš„ç•¶å‰ç‹€æ…‹ï¼ˆé–‹ç‡ˆ / é—œç‡ˆï¼‰ã€‚
* voice_statusï¼šå­˜å„²èªéŸ³æ§åˆ¶çš„ç‹€æ…‹ï¼ˆå·²å•Ÿå‹• / æœªå•Ÿå‹•ï¼‰ã€‚
* voice_threadï¼šèªéŸ³æ§åˆ¶åŸ·è¡Œç·’ï¼ˆThreadï¼‰ï¼Œç¢ºä¿èªéŸ³è¾¨è­˜èƒ½å¤ åœ¨ èƒŒæ™¯åŸ·è¡Œã€‚
* stop_voice_controlï¼šç”¨ä¾† å•Ÿå‹• / åœæ­¢ èªéŸ³æ§åˆ¶ã€‚

## ğŸ“Œ 4. è¨‚é–± MQTT ç‡ˆå…‰ç‹€æ…‹
```
def on_message(client, userdata, message):
    global light_status
    try:
        payload = json.loads(message.payload.decode())
        if "TurnOnLight" in payload:
            light_status = "é–‹ç‡ˆ" if payload["TurnOnLight"] else "é—œç‡ˆ"
    except json.JSONDecodeError:
        print("âŒ è§£æ MQTT è¨Šæ¯å¤±æ•—")

mqtt_client.subscribe(MQTT_TOPIC_TELEMETRY)
mqtt_client.on_message = on_message
```

é€™æ®µç¨‹å¼ç¢¼æœƒ è¨‚é–± ThingsBoard çš„ MQTT è¨Šæ¯ï¼Œç•¶ ESP8266 å‚³å›ç‡ˆå…‰ç‹€æ…‹ æ™‚ï¼Œç¨‹å¼æœƒæ›´æ–° light_statusã€‚

## ğŸ“Œ 5. Flask ä¼ºæœå™¨åˆå§‹åŒ–
```
app = Flask(__name__)

```
é€™æ˜¯ å•Ÿå‹• Flask Web ä¼ºæœå™¨ã€‚

## ğŸ“Œ 6. åˆå§‹åŒ– Webcam + AI åµæ¸¬
```
camera = cv2.VideoCapture(0)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
```
* cv2.VideoCapture(0)ï¼šé–‹å•Ÿ Webcamï¼ˆ0 ä»£è¡¨ç¬¬ä¸€å€‹æ”å½±æ©Ÿï¼‰ã€‚
* face_cascadeï¼šè¼‰å…¥ OpenCV äººè‡‰åµæ¸¬æ¨¡å‹ï¼Œç”¨ä¾†åµæ¸¬ç•«é¢ä¸­çš„äººè‡‰ã€‚

## ğŸ“Œ 7. å½±åƒä¸²æµï¼ˆé¡¯ç¤º AI åµæ¸¬æ¨™è¨˜æ¡†ï¼‰
```
def generate_frames():
    while True:
        success, frame = camera.read()
        if not success:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        _, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
```
é€™æ®µç¨‹å¼ç¢¼ï¼š

* è®€å– Webcam å½±åƒ
* è½‰æ›æˆ ç°éšåœ–åƒï¼Œé€²è¡Œ äººè‡‰åµæ¸¬
* å¦‚æœåµæ¸¬åˆ°äººè‡‰ï¼Œæœƒåœ¨ äººè‡‰å‘¨åœç•«å‡ºæ¨™è¨˜æ¡†
* å½±åƒæœƒå³æ™‚é¡¯ç¤ºåœ¨ç¶²é ä¸Š

## ğŸ“Œ 8. èªéŸ³æ§åˆ¶åŠŸèƒ½
```
def voice_control():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    while not stop_voice_control:
        with mic as source:
            print("ğŸ¤ èªéŸ³æ§åˆ¶ä¸­ï¼Œè«‹èªªï¼šé–‹ç‡ˆ / é—œç‡ˆ...")
            recognizer.adjust_for_ambient_noise(source, duration=1)
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=3)

        try:
            command = recognizer.recognize_google(audio, language="zh-TW")
            print(f"âœ… è¾¨è­˜æˆåŠŸ: {command}")

            if "é–‹ç‡ˆ" in command:
                mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": True}}))
            elif "é—œç‡ˆ" in command:
                mqtt_client.publish(MQTT_TOPIC_TELEMETRY, json.dumps({"method": "setLED", "params": {"enabled": False}}))
        except sr.UnknownValueError:
            print("âŒ èªéŸ³è¾¨è­˜å¤±æ•—")
        except sr.RequestError:
            print("âŒ ç„¡æ³•é€£ç·šè‡³ Google Speech API")
```
é€™æ®µç¨‹å¼ç¢¼ï¼š

* ç›£è½éº¥å…‹é¢¨
* è¾¨è­˜èªéŸ³å…§å®¹ï¼ˆã€Œé–‹ç‡ˆã€ / ã€Œé—œç‡ˆã€ï¼‰
* é€é MQTT ç™¼é€ç‡ˆå…‰æŒ‡ä»¤åˆ° ESP8266

## ğŸ“Œ 9. Flask ç¶²é ä»‹é¢
```
@app.route('/')
def home():
    return render_template_string('''
        <html>
        <head>
            <title>AI Camera & ESP8266 Control</title>
        </head>
        <body>
            <h1>AI Camera & ESP8266 Control</h1>
            <img src="/video_feed"><br><br>
            <h2 id="status">ç‡ˆå…‰ç‹€æ…‹: è®€å–ä¸­...</h2>
            <h2 id="voice_status">èªéŸ³æ§åˆ¶: æœªå•Ÿå‹•</h2>
            <button onclick="toggleVoice('start')">å•Ÿå‹•èªéŸ³æ§åˆ¶</button>
            <button onclick="toggleVoice('stop')">åœæ­¢èªéŸ³æ§åˆ¶</button>
            <br><br>
            <button onclick="toggleLight('on')">é–‹ç‡ˆ</button>
            <button onclick="toggleLight('off')">é—œç‡ˆ</button>
        </body>
        </html>
    ''')
```
* é¡¯ç¤ºå½±åƒä¸²æµ
* é¡¯ç¤ºç‡ˆå…‰ç‹€æ…‹
* é¡¯ç¤ºèªéŸ³æ§åˆ¶ç‹€æ…‹
* æä¾›ã€Œæ‰‹å‹•é–‹ç‡ˆ / é—œç‡ˆã€æŒ‰éˆ•
* æä¾›ã€Œå•Ÿå‹• / åœæ­¢èªéŸ³æ§åˆ¶ã€æŒ‰éˆ•

## ğŸ“Œ 10. å•Ÿå‹• Flask ä¼ºæœå™¨
```
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
```
é€™è¡Œä»£ç¢¼æœƒå•Ÿå‹• Flask ä¼ºæœå™¨ï¼Œå…è¨±å…¶ä»–è£ç½®ï¼ˆæ‰‹æ©Ÿ / é›»è…¦ï¼‰å­˜å–æ­¤ç¶²é ã€‚

## ğŸ“Œ ç¸½çµ
é€™å€‹ Flask æ‡‰ç”¨ç¨‹å¼ çµåˆ AI å½±åƒè¾¨è­˜ + MQTT + èªéŸ³æ§åˆ¶ï¼Œå¯ä»¥ï¼š âœ… æ‰‹å‹• / èªéŸ³æ§åˆ¶ ESP8266 ç‡ˆå…‰
âœ… å³æ™‚é¡¯ç¤ºå½±åƒä¸²æµ + AI äººè‡‰åµæ¸¬æ¨™è¨˜æ¡†
âœ… ç‡ˆå…‰ç‹€æ…‹ & èªéŸ³æ§åˆ¶ç‹€æ…‹å³æ™‚é¡¯ç¤º

ğŸš€ é€™æ˜¯å®Œæ•´çš„ AI + ç‰©è¯ç¶² MQTT æ§åˆ¶æ–¹æ¡ˆï¼ ğŸ¤ğŸ’¡ğŸ¥